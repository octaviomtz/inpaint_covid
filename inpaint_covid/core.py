# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['plot_3d_2', 'normalizePatches', 'len_multiple_32', 'mse_masked', 'mse_masked_loss',
           'read_covid_CT_and_mask', 'normalize_rotate', 'pad_volume_to_multiple_32', 'unet5', 'choose_loss',
           'plot_4_inpaints']

# Cell
import os
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import label
from scipy.ndimage import binary_dilation
from skimage import measure
from mpl_toolkits.mplot3d.art3d import Poly3DCollection

# Cell
from nilearn import image
import sys
from copy import copy
import string
import pandas as pd
from scipy.ndimage import binary_closing
from tqdm.notebook import tqdm
from matplotlib.gridspec import GridSpec
import nibabel as nib

# Cell
import tensorflow as tf
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dropout, Lambda
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import concatenate
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras import backend as K
from tensorflow.keras.layers import GaussianNoise
from scipy.ndimage import binary_erosion, binary_dilation
from tensorflow.keras.layers import LeakyReLU, ReLU
from tqdm.keras import TqdmCallback
from tensorflow.keras import backend as K

# Cell
def plot_3d_2(image, image2, threshold=-300, detail_speed=1, detail_speed2=1, figsize=(6,6)):
    '''Plot two 3D figures together'''
    # Position the scan upright,
    # so the head of the patient would be at the top facing the camera
    p = image.transpose(1,2,0)
    p = p.transpose(1,0,2)
    p = p[:,::-1,:]

    p2 = image2.transpose(1,2,0)
    p2 = p2.transpose(1,0,2)
    p2 = p2[:,::-1,:]

    verts, faces, _, _ = measure.marching_cubes_lewiner(p, threshold, step_size=detail_speed)
    verts2, faces2, _, _ = measure.marching_cubes_lewiner(p2, threshold, step_size=detail_speed2)

    fig = plt.figure(figsize=figsize)
    ax = fig.add_subplot(111, projection='3d')

    # Fancy indexing: `verts[faces]` to generate a collection of triangles
    mesh = Poly3DCollection(verts[faces], alpha=0.3)
    face_color = [0.5, 0.5, 1]
    mesh.set_facecolor(face_color)
    ax.add_collection3d(mesh)

    # figure 2
    mesh2 = Poly3DCollection(verts2[faces2], alpha=0.3)
    face_color2 = [1, 0.5, .5]
    mesh2.set_facecolor(face_color2)
    ax.add_collection3d(mesh2)

    ax.set_xlim(0, p.shape[0])
    ax.set_ylim(0, p.shape[1])
    ax.set_zlim(0, p.shape[2])
    plt.show()

# Cell
def normalizePatches(npzarray):
    '''normalize the lung region of a CT'''
    npzarray = npzarray
    maxHU = 400.
    minHU = -1000.
    npzarray = (npzarray - minHU) / (maxHU - minHU)
    npzarray[npzarray>1] = 1.
    npzarray[npzarray<0] = 0.
    return npzarray

# Cell
def len_multiple_32(ch, factor = 32):
    '''get the min length of a side that it is a multiple of 32 '''
    ch_max, ch_min = np.max(ch), np.min(ch)
    ch_len = ch_max - ch_min
    ch_len_multiple32 = ((ch_len-1) + factor) - ((ch_len-1) % factor)
    return ch_min, ch_max, ch_len_multiple32

# Cell
# https://stackoverflow.com/questions/45961428/make-a-custom-loss-function-in-keras
def mse_masked( pred , target, mask_target ):
    return tf.losses.mean_squared_error( pred*mask_target , target*mask_target )

def mse_masked_loss(mask_target):
    def mse_masked_return(pred, target):
        return mse_masked( pred , target, mask_target )
    return mse_masked_return

# Cell
def read_covid_CT_and_mask(path_source, filename):
    filename_mask = filename.replace('_ct','_seg')
    ct = nib.load(f'{path_source}Train/volume-{filename}')
    ct_seg = np.load(f'{path_source}segmentations/segmentation-{filename}.npz')
    ct_mask = nib.load(f'{path_source}Train/volume-{filename_mask}')
    ct = np.array(ct.get_fdata())
    ct_mask = np.array(ct_mask.get_fdata())
    ct_seg = ct_seg.f.arr_0
    return ct, ct_mask, ct_seg

# Cell
def normalize_rotate(ct, ct_mask, ct_seg):
    ct = normalizePatches(ct)
    ct = np.rot90(ct)
    ct_seg = normalizePatches(ct_seg)
    ct_mask = np.rot90(ct_mask)
    ct_seg = np.swapaxes(ct_seg, 0, 1)
    ct_seg = np.swapaxes(ct_seg, 1, 2)
    return ct, ct_mask, ct_seg

# Cell
def pad_volume_to_multiple_32(largest_component, ct, ct_mask, ct_seg, pad_val = 16):
    '''pad the volumes to size multiple of 32'''
    # pad to make sure subsequent cropping fits
    ct = np.pad(ct,((pad_val,pad_val),(pad_val,pad_val),(pad_val,pad_val)))
    ct_mask = np.pad(ct_mask,((pad_val,pad_val),(pad_val,pad_val),(pad_val,pad_val)))
    ct_seg = np.pad(ct_seg,((pad_val,pad_val),(pad_val,pad_val),(pad_val,pad_val)))
    # find coordinates of the lung and its next multiple of 32
    ch1, ch2, ch3 = np.where(largest_component>0)
    ch1_lim1, ch1_lim2, ch1_len32 = len_multiple_32(ch1)
    ch2_lim1, ch2_lim2, ch2_len32 = len_multiple_32(ch2)
    ch3_lim1, ch3_lim2, ch3_len32 = len_multiple_32(ch3)
    # apply the limits
    ct_small = ct[ch1_lim1-pad_val:ch1_lim1-pad_val+ch1_len32, ch2_lim1-pad_val:ch2_lim1-pad_val+ch2_len32, ch3_lim1-pad_val:ch3_lim1-pad_val+ch3_len32]
    ct_seg_small = ct_seg[ch1_lim1-pad_val:ch1_lim1-pad_val+ch1_len32, ch2_lim1-pad_val:ch2_lim1-pad_val+ch2_len32, ch3_lim1-pad_val:ch3_lim1-pad_val+ch3_len32]
    ct_mask_small = ct_mask[ch1_lim1-pad_val:ch1_lim1-pad_val+ch1_len32, ch2_lim1-pad_val:ch2_lim1-pad_val+ch2_len32, ch3_lim1-pad_val:ch3_lim1-pad_val+ch3_len32]
    return ct_small, ct_mask_small, ct_seg_small

# Cell
def unet5(ct_small, ch=32, g_noise= 0.3, act_max_value = 1, act_out_max_value = 1):
    IMG_CHANNELS = np.shape(ct_small)[-1]
    inputs = Input(np.shape(ct_small))
    c1 = Conv2D(ch, (3, 3), kernel_initializer='he_normal', padding='same') (inputs)
    if (g_noise > 0): c1 = GaussianNoise(g_noise) (c1)
    c1 = BatchNormalization()(c1)
    c1 = ReLU(max_value=act_max_value)(c1)
    # c1 = Dropout(0.1) (c1)
    c1 = Conv2D(ch, (3, 3), kernel_initializer='he_normal', padding='same') (c1)
    if (g_noise > 0): c1 = GaussianNoise(g_noise) (c1)
    c1 = BatchNormalization()(c1)
    c1 = ReLU(max_value=act_max_value)(c1)
    p1 = MaxPooling2D((2, 2)) (c1)

    c2 = Conv2D(ch*2, (3, 3), kernel_initializer='he_normal', padding='same') (p1)
    if (g_noise > 0): c2 = GaussianNoise(g_noise) (c2)
    c2 = BatchNormalization()(c2)
    c2 = ReLU(max_value=act_max_value)(c2)
    # c2 = Dropout(0.1) (c2)
    c2 = Conv2D(ch*2, (3, 3), kernel_initializer='he_normal', padding='same') (c2)
    if (g_noise > 0): c2 = GaussianNoise(g_noise) (c2)
    c2 = BatchNormalization()(c2)
    c2 = ReLU(max_value=act_max_value)(c2)
    p2 = MaxPooling2D((2, 2)) (c2)

    c3 = Conv2D(ch*4, (3, 3), kernel_initializer='he_normal', padding='same') (p2)
    if (g_noise > 0): c3 = GaussianNoise(g_noise) (c3)
    c3 = BatchNormalization()(c3)
    c3 = ReLU(max_value=act_max_value)(c3)
    # c3 = Dropout(0.2) (c3)
    c3 = Conv2D(ch*4, (3, 3), kernel_initializer='he_normal', padding='same') (c3)
    if (g_noise > 0): c3 = GaussianNoise(g_noise) (c3)
    c3 = BatchNormalization()(c3)
    c3 = ReLU(max_value=act_max_value)(c3)
    p3 = MaxPooling2D((2, 2)) (c3)

    c4 = Conv2D(ch*8, (3, 3), kernel_initializer='he_normal', padding='same') (p3)
    if (g_noise > 0): c4 = GaussianNoise(g_noise) (c4)
    c4 = BatchNormalization()(c4)
    c4 = ReLU(max_value=act_max_value)(c4)
    # c4 = Dropout(0.2) (c4)
    c4 = Conv2D(ch*8, (3, 3), kernel_initializer='he_normal', padding='same') (c4)
    if (g_noise > 0): c4 = GaussianNoise(g_noise) (c4)
    c4 = BatchNormalization()(c4)
    c4 = ReLU(max_value=act_max_value)(c4)
    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)

    c5 = Conv2D(ch*16, (3, 3), kernel_initializer='he_normal', padding='same') (p4)
    if (g_noise > 0): c5 = GaussianNoise(g_noise) (c5)
    c5 = BatchNormalization()(c5)
    c5 = ReLU(max_value=act_max_value)(c5)
    # c5 = Dropout(0.3) (c5)
    c5 = Conv2D(ch*16, (3, 3), kernel_initializer='he_normal', padding='same') (c5)
    if (g_noise > 0): c5 = GaussianNoise(g_noise) (c5)
    c5 = BatchNormalization()(c5)
    c5 = ReLU(max_value=act_max_value)(c5)

    out_inter = c5

    u6 = Conv2DTranspose(ch*4, (2, 2), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(ch*8, (3, 3), kernel_initializer='he_normal', padding='same') (u6)
    if (g_noise > 0): c6 = GaussianNoise(g_noise) (c6)
    c6 = BatchNormalization()(c6)
    c6 = ReLU(max_value=act_max_value)(c6)
    # c6 = Dropout(0.2) (c6)
    c6 = Conv2D(ch*8, (3, 3), kernel_initializer='he_normal', padding='same') (c6)
    if (g_noise > 0): c6 = GaussianNoise(g_noise) (c6)
    c6 = BatchNormalization()(c6)
    c6 = ReLU(max_value=act_max_value)(c6)

    u7 = Conv2DTranspose(ch*2, (2, 2), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(ch*4, (3, 3), kernel_initializer='he_normal', padding='same') (u7)
    if (g_noise > 0): c7 = GaussianNoise(g_noise) (c7)
    c7 = BatchNormalization()(c7)
    c7 = ReLU(max_value=act_max_value)(c7)
    # c7 = Dropout(0.2) (c7)
    c7 = Conv2D(ch*4, (3, 3), kernel_initializer='he_normal', padding='same') (c7)
    if (g_noise > 0): c7 = GaussianNoise(g_noise) (c7)
    c7 = BatchNormalization()(c7)
    c7 = ReLU(max_value=act_max_value)(c7)

    u8 = Conv2DTranspose(ch, (2, 2), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(ch*2, (3, 3), kernel_initializer='he_normal', padding='same') (u8)
    if (g_noise > 0): c8 = GaussianNoise(g_noise) (c8)
    c8 = BatchNormalization()(c8)
    c8 = ReLU(max_value=act_max_value)(c8)
    # c8 = Dropout(0.1) (c8)
    c8 = Conv2D(ch*2, (3, 3), kernel_initializer='he_normal', padding='same') (c8)
    if (g_noise > 0): c8 = GaussianNoise(g_noise) (c8)
    c8 = BatchNormalization()(c8)
    c8 = ReLU(max_value=act_max_value)(c8)

    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(ch, (3, 3), kernel_initializer='he_normal', padding='same') (u9)
    if (g_noise > 0): c9 = GaussianNoise(g_noise) (c9)
    c9 = BatchNormalization()(c9)
    c9 = ReLU(max_value=act_max_value)(c9)
    # c9 = Dropout(0.1) (c9)
    c9 = Conv2D(ch, (3, 3), kernel_initializer='he_normal', padding='same') (c9)
    if (g_noise > 0): c9 = GaussianNoise(g_noise) (c9)
    c9 = BatchNormalization()(c9)
    c9 = ReLU(max_value=act_max_value)(c9)

    outputs = Conv2D(IMG_CHANNELS, (1, 1)) (c9)
    outputs = ReLU(max_value=act_out_max_value)(outputs)
    model = Model(inputs=[inputs], outputs=[outputs])
    return model

# Cell
def choose_loss(mask_target, mask_target2, mask_target3, LOSS_USED=0):
    if LOSS_USED == 2:
        loss_masked = mse_masked_loss(mask_target=mask_target2)
        mask_used = mask_target2
    elif LOSS_USED == 3:
        loss_masked = mse_masked_loss(mask_target=mask_target3)
        mask_used = mask_target3
    else:
        loss_masked = mse_masked_loss(mask_target=mask_target)
        mask_used = mask_target
    return loss_masked, mask_used

# Cell
def plot_4_inpaints(predicted_all, epochs_saved, target, mask_used, target_mask3, act_max_value, act_out_max_value, results_all, g_noise, blend='add', slice_mask=0):
    color1 = "#3F5D7D"
    color2 = "#990F02"
    fig=plt.figure(figsize=(30,6));
    heights = [3,1]
    gs=GridSpec(2,9, height_ratios=heights) # 2 rows, 3 columns
    ax1=fig.add_subplot(gs[0,0]) # First row, first column
    ax2=fig.add_subplot(gs[0,1]) # First row, second column
    ax3=fig.add_subplot(gs[0,2]) # First row, third column
    ax4=fig.add_subplot(gs[0,3])
    ax5=fig.add_subplot(gs[0,4])
    ax6=fig.add_subplot(gs[0,5])
    ax7=fig.add_subplot(gs[0,6])
    ax8=fig.add_subplot(gs[0,7])
    ax9=fig.add_subplot(gs[0,8])
    ax10=fig.add_subplot(gs[1,:])


    label0 = f'epochs={epochs_saved[-4]}\nact_max_value={act_max_value}\nact_out_max_value={act_out_max_value}'
    label1 = f'epochs={epochs_saved[-3]}\nact_max_value={act_max_value}\nact_out_max_value={act_out_max_value}'
    label2 = f'epochs={epochs_saved[-2]}\nact_max_value={act_max_value}\nact_out_max_value={act_out_max_value}'
    label3 = f'epochs={epochs_saved[-1]}\nact_max_value={act_max_value}\nact_out_max_value={act_out_max_value}\ng_noise={g_noise}'
    ax1.imshow(mask_used[0,:,:,slice_mask], vmin=0, vmax=1)
    for i in [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9]: i.axis('off')
    y_text = 60
    ax2.imshow(predicted_all[-4], vmin=0, vmax=1); ax2.text(10, y_text, label0, c='r')
    ax3.imshow(np.abs(target - predicted_all[-4]), vmin=0, vmax=1) if blend=='substract' else ax3.imshow(target*~target_mask3 + predicted_all[-4]*target_mask3, vmin=0, vmax=1)
    ax4.imshow(predicted_all[-3], vmin=0, vmax=1); ax4.text(10, y_text, label1, c='r')
    ax5.imshow(np.abs(target - predicted_all[-3]), vmin=0, vmax=1) if blend=='substract' else ax5.imshow(target*~target_mask3 + predicted_all[-3]*target_mask3, vmin=0, vmax=1)
    ax6.imshow(predicted_all[-2], vmin=0, vmax=1); ax6.text(10, y_text, label2, c='r')
    ax7.imshow(np.abs(target - predicted_all[-2]), vmin=0, vmax=1) if blend=='substract' else ax7.imshow(target*~target_mask3 + predicted_all[-2]*target_mask3, vmin=0, vmax=1)
    ax8.imshow(predicted_all[-1], vmin=0, vmax=1); ax8.text(10, y_text+10, label3, c='r')
    ax9.imshow(np.abs(target - predicted_all[-1]), vmin=0, vmax=1) if blend=='substract' else ax9.imshow(target*~target_mask3 + predicted_all[-1]*target_mask3, vmin=0, vmax=1)
    ax10.semilogy(results_all, label = label3, color=color1)
    ax10.semilogy(np.asarray(epochs_saved)-1, np.asarray(results_all)[np.asarray(epochs_saved)-1], marker='.', linestyle='None', markersize=20, color=color1)
    ax10.semilogy(np.asarray(epochs_saved[-4:])-1, np.asarray(results_all)[np.asarray(epochs_saved[-4:])-1], marker='.', linestyle='None', markersize=20, color=color1, markeredgecolor=color2, markeredgewidth=2)
    ax10.legend();
    ax10.spines["top"].set_visible(False)
    ax10.spines["right"].set_visible(False)
    ax10.get_xaxis().tick_bottom()
    ax10.get_yaxis().tick_left()
    fig.tight_layout()